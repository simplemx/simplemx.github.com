由于要买家电，但是家电价格就是个坑，如果等到五一国庆等，实在是难以说，现在的价钱说不定年中都会是很不错的价格了。反倒国庆等的价钱会比较坑。

为了钱着想，还是想着能省点就省点看看什么价钱优惠再出手吧，于是smzdm就是个挺好的网站了，可是呢，smzdm信息量太大了，而且更多是海购类的。对于我这种想在京东亚马逊上面买家电实在是太烦恼了。

所以就想着自己写个爬虫来看看。

由于开始想在Chrome上安装个插件，点击插件就能看到我想买的东西的价钱变化和优惠信息等，于是捣腾了下Chrome的插件开发，插件倒是很容易开发的，一个manifest.json就配置好了，当然咯还有好多配置等的，但是目前我用不到了。

页面出来了，下面需要的是爬虫，Ajax捉取HTML然后解析Document应该是最简单的方式，但为了练手，我选择了在GAE上部署个Python应用爬虫来作为后台服务。

于是捣腾了下Python的爬虫，Python是很适合写爬虫的，的确几行代码就可以爬到想要的HTML了，不过urllib和urllib2实在是不想吐槽了。

然后使用BeautifulSoup来进行HTML解析，看上去还没碰到什么坑，一下子就可以爬到亚马逊上想要的信息了。

这里还有字符集的处理等，这个可以在HTML里捉取charset的设置，然后进行不同字符集的编码。

encode = soup.meta.get("charset")
if not encode:
    encode = soup.meta.get("content-type")
    if not encode:
        encode = soup.meta.get("content")
        pass

然后开始爬京东，之前就了解过爬虫最讨厌的是碰到AJAX的了，京东的页面实在是令我捉狂，无论是价格等等信息都是AJAX请求回来的，看着页面那一堆的HTTP请求，我在想这页面这样处理妥当么？

怎么处理AJAX请求呢？目前想到的最简单方法就是捉取它的AJAX请求来爬了，不过这样很什么，当然如果只是简单的处理那肯定最快也简单的了，但如果还牵涉到多个AJAX啊JS啊等，那么就要将目标页面都弄清楚才能做了，这样很坑爹，那么可以模拟浏览器来完成这样的场景。

使用Python来模拟浏览器，可以有下面几种方式：

1.使用selenium

使用这种方式就是让Python打开一个浏览器然后加载页面，这样会打开一个浏览器窗口，在GAE的场景下完全不能用，而且就算是本机，弹出这么一个窗口实在是不能接受。

2.phantom.js

这种方式可以结合selenium来完成无需弹出浏览器窗口就能模拟浏览器加载页面，不过呢，鉴于GAE上的环境，这个要部署再上面基本是不可能的。

3.QT

同phantom.js，要部署再GAE上真的没多大可能。

4.splinter

这个还没尝试，后续可以尝试下行不行。

上述的方法基本都不能在GAE上跑通，而鉴于京东那暴多的AJAX请求，我想了要真的捉取京东目前来看只有捉取AJAX请求才比较可行。

于是一下子捉取亚马逊的插件出来了，但是京东的被卡住了，不是不能捉，而是感觉代价太大了。

想了下，或者不放GAE也可以，本地跑也可以啊，这样比较妥当，这个是后续的改造点了。

